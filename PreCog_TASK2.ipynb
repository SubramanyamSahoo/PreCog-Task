{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opnI8XfiTW3N",
        "outputId": "5d96beb8-f237-497d-8d09-255f4f658d2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3IuhoGI1pA8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Load the dataset from the provided JSONL file\n",
        "file_path = '/content/drive/MyDrive/LLMs/alpha.jsonl'\n",
        "dataset = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P32NJfyZ-nuO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "55d7e84c-4282-4be4-d9ae-e0533c5b8860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
            "Error decoding JSON: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
            "Error decoding JSON: Extra data: line 1 column 14 (char 13)\n",
            "Error decoding JSON: Extra data: line 1 column 14 (char 13)\n",
            "Error decoding JSON: Extra data: line 1 column 19 (char 18)\n",
            "Error decoding JSON: Extra data: line 1 column 65 (char 64)\n",
            "Error decoding JSON: Extra data: line 1 column 68 (char 67)\n",
            "Error decoding JSON: Extra data: line 1 column 68 (char 67)\n",
            "Error decoding JSON: Extra data: line 1 column 68 (char 67)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "string indices must be integers",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ea589e924534>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Extract law description, situation, true output, and predicted outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0minstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'instruction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mtrue_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'true_output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mpredicted_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "\n",
        "# Path to the dataset file\n",
        "file_path = '/content/drive/MyDrive/LLMs/alpha.jsonl'  # Replace with your file path\n",
        "\n",
        "# Initialize sets to store unique values\n",
        "unique_identity_terms = set()\n",
        "unique_genders = set()\n",
        "unique_actions = set()\n",
        "\n",
        "# Initialize a list to store prompts and verdicts\n",
        "prompts_data = []\n",
        "\n",
        "# Read the .jsonl file\n",
        "with open(file_path, 'r') as file:\n",
        "  for line in file:\n",
        "    # Skip empty lines (optional)\n",
        "    if not line.strip():\n",
        "      continue\n",
        "\n",
        "    try:\n",
        "      data = json.loads(line.strip())\n",
        "    except json.JSONDecodeError as e:\n",
        "      print(\"Error decoding JSON:\", e)\n",
        "      continue  # Skip the line if there's a decoding error\n",
        "\n",
        "    # Extract law description, situation, true output, and predicted outputs\n",
        "    instruction = data['instruction']\n",
        "    true_output = data['true_output']\n",
        "    predicted_outputs = data['predicted_output']\n",
        "\n",
        "    # Parse the situation to extract identity term, gender, and action\n",
        "    situation_start = instruction.index(\"Situation:\") + len(\"Situation:\")\n",
        "    situation = instruction[situation_start:].strip()\n",
        "\n",
        "    identity_gender_action_pattern = re.compile(r'(\\w+), a (\\w+) (\\w+), has been accused of committing a (\\w+)')\n",
        "    match = identity_gender_action_pattern.search(situation)\n",
        "\n",
        "    if match:\n",
        "      name = match.group(1)\n",
        "      identity_term = match.group(2)\n",
        "      gender = match.group(3)\n",
        "      action = match.group(4)\n",
        "\n",
        "      unique_identity_terms.add(identity_term)\n",
        "      unique_genders.add(gender)\n",
        "      unique_actions.add(action)\n",
        "\n",
        "      # Store the prompt and verdict data\n",
        "      prompts_data.append({\n",
        "          'Law Description': instruction.split('\\n')[0].strip(),\n",
        "          'Identity Term': identity_term,\n",
        "          'Gender': gender,\n",
        "          'Action': action,\n",
        "          'True Verdict': true_output,\n",
        "          'Predicted Verdicts': predicted_outputs\n",
        "      })\n",
        "\n",
        "# Convert prompts data to DataFrame for analysis\n",
        "prompts_df = pd.DataFrame(prompts_data)\n",
        "\n",
        "# Analyze the distribution of features\n",
        "\n",
        "# Analyze identity terms\n",
        "print(\"Unique Identity Terms:\")\n",
        "print(unique_identity_terms)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Analyze genders\n",
        "print(\"Unique Genders:\")\n",
        "print(unique_genders)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Analyze actions\n",
        "print(\"Unique Actions:\")\n",
        "print(unique_actions)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Analyze true verdicts (already available in prompts_df)\n",
        "# You can use prompts_df['True Verdict'].value_counts() to get the distribution\n",
        "\n",
        "# Analyze predicted verdicts (requires iterating through the list)\n",
        "# You can loop through prompts_df['Predicted Verdicts'] and analyze the distribution\n",
        "\n",
        "# ... (further analysis of predicted verdicts or other features)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VGYPsPcVsOgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FHJQNCO7rzpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QbISofVbrDzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PU4s2HHuq1BU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QsFgbykMqwj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q44tcd4iqs1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tiKQ37NXqprt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CmBrk1BVo7B2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B8iTHicwmoii"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}